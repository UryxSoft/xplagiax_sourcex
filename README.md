# xplagiax_sourcex
data source research services

# 1. Construir
docker-compose up --build

# 2. Probar
curl -X POST http://localhost:5000/api/similarity-search \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      "machine learning",
      "en",
      [
        ["page1", "para1", "Neural networks are computational models"],
        ["page1", "para2", "Deep learning uses multiple layers"]
      ]
    ]
  }'

# 3. Ver estadÃ­sticas FAISS
curl http://localhost:5000/api/faiss/stats


# BÃºsqueda bÃ¡sica
curl -X POST http://localhost:5000/api/similarity-search \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      "machine learning",
      "en",
      [
        ["page1", "para1", "Neural networks are computational models inspired by biological neurons"],
        ["page1", "para2", "Deep learning uses multiple layers to extract features"],
        ["page2", "para1", "Convolutional networks excel at image recognition tasks"]
      ]
    ]
  }'

# BÃºsqueda con fuentes especÃ­ficas
curl -X POST http://localhost:5000/api/similarity-search \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      "artificial intelligence",
      "en",
      [
        ["page1", "para1", "AI systems can learn from data"]
      ]
    ],
    "sources": ["semantic_scholar", "arxiv", "pubmed"]
  }'

# BÃºsqueda sin FAISS (solo APIs)
curl -X POST http://localhost:5000/api/similarity-search \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      "quantum computing",
      "en",
      [
        ["page1", "para1", "Quantum computers use qubits"]
      ]
    ],
    "use_faiss": false
  }'

# BÃºsqueda en espaÃ±ol
curl -X POST http://localhost:5000/api/similarity-search \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      "aprendizaje automÃ¡tico",
      "es",
      [
        ["pagina1", "parrafo1", "Las redes neuronales son modelos computacionales"],
        ["pagina1", "parrafo2", "El aprendizaje profundo utiliza mÃºltiples capas"]
      ]
    ]
  }'


# BÃºsqueda simple
curl -X POST http://localhost:5000/api/faiss/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "deep learning neural networks"
  }'

# BÃºsqueda con parÃ¡metros personalizados
curl -X POST http://localhost:5000/api/faiss/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "convolutional neural networks image recognition",
    "k": 20,
    "threshold": 0.75
  }'

# ğŸ”¬ xplagiax_sourcex - Academic Search Service

Sistema de bÃºsqueda acadÃ©mica con similitud semÃ¡ntica utilizando FAISS, mÃºltiples APIs y machine learning.

## ğŸš€ Inicio RÃ¡pido

### 1. ConfiguraciÃ³n

```bash
# Clonar repositorio
git clone <repo-url>
cd xplagiax_sourcex

# Copiar configuraciÃ³n
cp .env.example .env

# Generar secretos (Linux/Mac)
echo "REDIS_PASSWORD=$(openssl rand -base64 32)" >> .env
echo "FLASK_SECRET_KEY=$(openssl rand -base64 48)" >> .env

# Editar .env con tu configuraciÃ³n
nano .env
```

### 2. Construir y Ejecutar

```bash
# Construir e iniciar servicios
docker-compose up --build

# En segundo plano
docker-compose up -d

# Ver logs
docker-compose logs -f app
```

### 3. Verificar Estado

```bash
# Health check
curl http://localhost:5000/api/health

# EstadÃ­sticas FAISS
curl http://localhost:5000/api/faiss/stats
```

## ğŸ“Š Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask + Gunicorn      â”‚
â”‚   (4 workers)           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º Redis (CachÃ©)
       â”œâ”€â”€â–º FAISS (BÃºsqueda vectorial)
       â””â”€â”€â–º APIs Externas:
            â€¢ Crossref
            â€¢ PubMed
            â€¢ Semantic Scholar
            â€¢ arXiv
            â€¢ OpenAlex
            â€¢ Europe PMC
            â€¢ DOAJ
            â€¢ Zenodo
```

## ğŸ”Œ Endpoints Principales

### BÃºsqueda de Similitud

```bash
POST /api/similarity-search
Content-Type: application/json

{
  "data": [
    "machine learning",
    "en",
    [
      ["page1", "para1", "Neural networks are computational models"],
      ["page1", "para2", "Deep learning uses multiple layers"]
    ]
  ],
  "use_faiss": true,
  "sources": ["semantic_scholar", "arxiv"]
}
```

**Respuesta:**

```json
{
  "results": [
    {
      "fuente": "semantic_scholar",
      "texto_original": "Neural networks are...",
      "texto_encontrado": "This paper presents...",
      "porcentaje_match": 89.2,
      "documento_coincidente": "Deep Learning Book",
      "autor": "Goodfellow",
      "type_document": "article"
    }
  ],
  "count": 10,
  "processed_texts": 2,
  "faiss_enabled": true
}
```

### FAISS

```bash
# EstadÃ­sticas
GET /api/faiss/stats

# BÃºsqueda directa
POST /api/faiss/search
{
  "query": "deep learning neural networks",
  "k": 20,
  "threshold": 0.75
}

# Guardar Ã­ndice
POST /api/faiss/save

# Backup
POST /api/faiss/backup

# Limpiar
POST /api/faiss/clear
```

### Monitoreo

```bash
# Health check
GET /api/health

# MÃ©tricas Prometheus
GET /api/metrics

# DiagnÃ³stico completo
GET /api/diagnostics/full

# Validar APIs externas
POST /api/validate-apis

# Profiler
GET /api/profiler/stats
GET /api/profiler/bottlenecks?top=10
```

### AdministraciÃ³n

```bash
# Limpiar cachÃ©
POST /api/cache/clear

# Reiniciar rate limits
POST /api/reset-limits

# Benchmark
POST /api/benchmark
{
  "num_texts": 50
}
```

## ğŸ” Seguridad

### Rate Limiting

- **Global**: 200 req/dÃ­a, 50 req/hora por IP
- **BÃºsqueda**: 10 req/minuto por IP

### ValidaciÃ³n de Entrada

- SanitizaciÃ³n automÃ¡tica de HTML/XSS
- LÃ­mites de longitud
- ValidaciÃ³n de tipos

### AutenticaciÃ³n Redis

Configurar contraseÃ±a en `.env`:

```bash
REDIS_PASSWORD=your_strong_password
```

### CORS

Configurar dominios permitidos:

```bash
ALLOWED_ORIGINS=https://domain1.com,https://domain2.com
```

## ğŸ“ˆ OptimizaciÃ³n

### Estrategias FAISS

| TamaÃ±o | Estrategia | Velocidad | Memoria | Recall |
|--------|------------|-----------|---------|--------|
| <10k | Flat | âš¡âš¡âš¡ | ğŸ”´ğŸ”´ğŸ”´ | 100% |
| 10k-100k | HNSW | âš¡âš¡ | ğŸ”´ğŸ”´ | 95% |
| 100k-1M | IVF+Flat | âš¡ | ğŸ”´ | 90% |
| >1M | IVF+PQ | ğŸŒ | âœ… | 85% |

FAISS auto-upgrade automÃ¡ticamente segÃºn el tamaÃ±o.

### CachÃ©

- **Redis**: 24 horas de TTL
- **SerializaciÃ³n**: orjson (5x mÃ¡s rÃ¡pido que pickle)
- **CompresiÃ³n**: LRU con 512MB lÃ­mite

### Performance

- **HTTP/2**: Pool de 20 conexiones persistentes
- **Batch processing**: 64 embeddings por batch
- **Async/await**: BÃºsquedas paralelas en APIs

## ğŸ§ª Testing

```bash
# Instalar dependencias de testing
pip install pytest pytest-asyncio pytest-cov

# Ejecutar tests
pytest

# Con cobertura
pytest --cov=. --cov-report=html

# Ver reporte
open htmlcov/index.html
```

## ğŸ“Š MÃ©tricas

### Prometheus

```bash
# Scrape endpoint
GET /api/metrics
```

MÃ©tricas disponibles:
- `api_requests_total`: Total de requests
- `api_latency_ms`: Latencia promedio
- `api_error_rate`: % de errores
- `cache_hit_rate`: % de cache hits
- `faiss_indexed_papers`: Papers en FAISS

### Grafana Dashboard

```json
{
  "panels": [
    {
      "title": "Request Rate",
      "targets": ["rate(api_requests_total[5m])"]
    },
    {
      "title": "FAISS Index Size",
      "targets": ["faiss_indexed_papers"]
    }
  ]
}
```

## ğŸ› Troubleshooting

### Error: FAISS no disponible

```bash
# Instalar FAISS
pip install faiss-cpu

# O para GPU
pip install faiss-gpu
```

### Error: Redis connection refused

```bash
# Verificar que Redis estÃ© corriendo
docker-compose ps

# Ver logs
docker-compose logs redis

# Reiniciar servicios
docker-compose restart
```

### Memoria insuficiente

```bash
# Limpiar Ã­ndice FAISS
curl -X POST http://localhost:5000/api/faiss/clear

# O reducir lÃ­mites en docker-compose.yml
deploy:
  resources:
    limits:
      memory: 1G  # Reducir de 2G a 1G
```

### Ãndice corrupto

```bash
# Auto-reparaciÃ³n
curl -X POST http://localhost:5000/api/faiss/save

# O limpiar y reconstruir
curl -X POST http://localhost:5000/api/faiss/clear
```

## ğŸ”„ Backup y RecuperaciÃ³n

### Backup Manual

```bash
# Backup FAISS
curl -X POST http://localhost:5000/api/faiss/backup

# Copiar datos
docker cp academic_search_app:/app/backups ./backups_local
```

### Backup AutomÃ¡tico (Cron)

```bash
# Agregar a crontab
0 2 * * * docker exec academic_search_app curl -X POST http://localhost:5000/api/faiss/backup
```

### RestauraciÃ³n

```bash
# Copiar backup
docker cp ./backups_local/faiss_20231215_020000/ academic_search_app:/app/data/

# Renombrar archivos
docker exec academic_search_app mv data/faiss_20231215_020000/faiss_index.index data/faiss_index.index

# Reiniciar
docker-compose restart app
```

## ğŸ“ Logs

### Ver Logs

```bash
# Tiempo real
docker-compose logs -f app

# Ãšltimas 100 lÃ­neas
docker-compose logs --tail=100 app

# Logs de archivo
docker exec academic_search_app tail -f logs/app_$(date +%Y%m%d).log
```

### Niveles de Log

Configurar en `.env`:

```bash
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL
```

## ğŸš€ ProducciÃ³n

### Checklist

- [ ] Cambiar `REDIS_PASSWORD` y `FLASK_SECRET_KEY`
- [ ] Configurar `ALLOWED_ORIGINS` con dominios reales
- [ ] Establecer `LOG_LEVEL=WARNING`
- [ ] Configurar backup automÃ¡tico
- [ ] Configurar monitoreo (Prometheus + Grafana)
- [ ] Habilitar HTTPS en reverse proxy
- [ ] Limitar recursos en docker-compose
- [ ] Configurar alertas

### Reverse Proxy (Nginx)

```nginx
server {
    listen 80;
    server_name api.yourdomain.com;

    location / {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

### Escalado

```bash
# Aumentar workers de Gunicorn
# En Dockerfile, cambiar:
CMD ["gunicorn", "--workers", "8", ...]  # De 4 a 8

# Escalar con Docker Compose
docker-compose up -d --scale app=3
```

## ğŸ“š DocumentaciÃ³n Adicional

- [FAISS Usage Guide](FAISS_USAGE.md)
- [API Reference](docs/API.md)
- [Architecture](docs/ARCHITECTURE.md)

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear branch (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

## ğŸ‘¥ Autores

- **Equipo xplagiax** - Desarrollo inicial

## ğŸ™ Agradecimientos

- Sentence Transformers
- FAISS (Facebook AI)
- Flask
- Todas las APIs acadÃ©micas utilizadas

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USUARIO ENVÃA REQUEST                                           â”‚
â”‚ POST /api/similarity-search                                     â”‚
â”‚ {                                                               â”‚
â”‚   "data": [                                                     â”‚
â”‚     "machine learning",                                         â”‚
â”‚     "en",                                                       â”‚
â”‚     [                                                           â”‚
â”‚       ["page1", "para1", "Neural networks are models"],        â”‚
â”‚       ["page1", "para2", "Deep learning uses layers"]          â”‚
â”‚     ]                                                           â”‚
â”‚   ]                                                             â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 1: Flask recibe el request                                â”‚
â”‚ Archivo: app.py lÃ­nea 43                                       â”‚
â”‚ FunciÃ³n: @app.route('/api/similarity-search')                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 2: ValidaciÃ³n de datos                                    â”‚
â”‚ Archivo: app.py lÃ­neas 51-77                                   â”‚
â”‚                                                                 â”‚
â”‚ âœ“ Verifica que exista campo 'data'                            â”‚
â”‚ âœ“ Extrae: theme = "machine learning"                          â”‚
â”‚ âœ“ Extrae: idiom = "en"                                        â”‚
â”‚ âœ“ Extrae: texts = [[page, para, text], ...]                  â”‚
â”‚ âœ“ Extrae: sources = None (opcional)                           â”‚
â”‚ âœ“ Extrae: use_faiss = True (default)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 3: Llama al procesador principal                          â”‚
â”‚ Archivo: app.py lÃ­nea 80                                       â”‚
â”‚                                                                 â”‚
â”‚ process_similarity_batch(                                       â”‚
â”‚   texts,              # Los pÃ¡rrafos a buscar                  â”‚
â”‚   theme,              # "machine learning"                     â”‚
â”‚   idiom,              # "en"                                   â”‚
â”‚   redis_client,       # Para cachÃ©                             â”‚
â”‚   http_client,        # Para APIs                              â”‚
â”‚   rate_limiter,       # Control de rate limits                 â”‚
â”‚   sources,            # APIs a usar                            â”‚
â”‚   use_faiss           # Si usar FAISS o no                     â”‚
â”‚ )                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 4: Inicio del procesamiento batch                         â”‚
â”‚ Archivo: search_service.py lÃ­nea 49                            â”‚
â”‚ FunciÃ³n: process_similarity_batch()                            â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Inicia timer para mÃ©tricas                                   â”‚
â”‚ â€¢ Verifica salud del Ã­ndice FAISS                             â”‚
â”‚ â€¢ Agrupa textos Ãºnicos (deduplicaciÃ³n)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 5: Preprocesamiento de textos                            â”‚
â”‚ Archivo: search_service.py lÃ­neas 61-80                       â”‚
â”‚                                                                 â”‚
â”‚ Para cada texto:                                               â”‚
â”‚   1. preprocess_text_cached()                                  â”‚
â”‚      â€¢ Convierte a minÃºsculas                                  â”‚
â”‚      â€¢ Elimina caracteres especiales                           â”‚
â”‚      â€¢ Normaliza espacios                                      â”‚
â”‚                                                                 â”‚
â”‚   Entrada: "Neural networks are computational Models!"         â”‚
â”‚   Salida: "neural networks are computational models"           â”‚
â”‚                                                                 â”‚
â”‚   2. remove_stopwords_optimized()                              â”‚
â”‚      â€¢ Tokeniza el texto                                       â”‚
â”‚      â€¢ Elimina palabras comunes (are, the, is...)             â”‚
â”‚                                                                 â”‚
â”‚   Entrada: "neural networks are computational models"          â”‚
â”‚   Salida: "neural networks computational models"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 6: Verificar cachÃ© Redis                                  â”‚
â”‚ Archivo: search_service.py lÃ­nea 70                            â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Genera clave Ãºnica: hash(theme + idiom + texto)             â”‚
â”‚ â€¢ Busca en Redis: "search:abc123..."                          â”‚
â”‚                                                                 â”‚
â”‚ SI ENCUENTRA en cachÃ©:                                         â”‚
â”‚   â†’ Retorna resultados inmediatamente âœ…                       â”‚
â”‚   â†’ Salta al PASO 14                                           â”‚
â”‚                                                                 â”‚
â”‚ SI NO ENCUENTRA:                                               â”‚
â”‚   â†’ ContinÃºa al PASO 7 â¬                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 7: BÃºsqueda en FAISS (si disponible)                     â”‚
â”‚ Archivo: search_service.py lÃ­neas 85-100                      â”‚
â”‚                                                                 â”‚
â”‚ SI FAISS tiene papers indexados:                               â”‚
â”‚   1. Llama a faiss_index.search_batch()                       â”‚
â”‚      â€¢ Genera embeddings de las queries                        â”‚
â”‚      â€¢ Busca vectores similares en el Ã­ndice                   â”‚
â”‚      â€¢ Retorna top 20 por query                                â”‚
â”‚                                                                 â”‚
â”‚   Ejemplo:                                                      â”‚
â”‚   Query: "neural networks computational models"                â”‚
â”‚   â†“                                                             â”‚
â”‚   Embedding: [0.12, -0.45, 0.78, ..., 0.34] (384 dims)       â”‚
â”‚   â†“                                                             â”‚
â”‚   FAISS busca vectores similares                               â”‚
â”‚   â†“                                                             â”‚
â”‚   Encuentra:                                                    â”‚
â”‚     - "Deep Learning Book" (89.2% match)                       â”‚
â”‚     - "Neural Network Basics" (85.7% match)                    â”‚
â”‚     - "CNN Tutorial" (82.1% match)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 8: Evaluar resultados de FAISS                           â”‚
â”‚ Archivo: search_service.py lÃ­neas 102-122                     â”‚
â”‚                                                                 â”‚
â”‚ Para cada query:                                               â”‚
â”‚   SI encontrÃ³ â‰¥5 resultados en FAISS:                         â”‚
â”‚     â†’ Convierte a SearchResult                                 â”‚
â”‚     â†’ Guarda en cachÃ©                                          â”‚
â”‚     â†’ Marca como "completo" âœ…                                 â”‚
â”‚                                                                 â”‚
â”‚   SI encontrÃ³ <5 resultados:                                   â”‚
â”‚     â†’ Marca para buscar en APIs ğŸŒ                            â”‚
â”‚     â†’ ContinÃºa al PASO 9 â¬                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 9: BÃºsqueda en APIs externas (si es necesario)             â”‚
â”‚ Archivo: search_service.py lÃ­nea 127                            â”‚
â”‚ FunciÃ³n: search_all_sources()                                   â”‚
â”‚                                                                 â”‚
â”‚ Busca en PARALELO en todas las APIs:                            â”‚
â”‚   â€¢ Crossref                                                    â”‚
â”‚   â€¢ PubMed                                                      â”‚
â”‚   â€¢ Semantic Scholar                                            â”‚
â”‚   â€¢ arXiv                                                       â”‚
â”‚   â€¢ OpenAlex                                                    â”‚
â”‚   â€¢ Europe PMC                                                  â”‚
â”‚   â€¢ DOAJ                                                        â”‚
â”‚   â€¢ Zenodo                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 10: Detalle de bÃºsqueda en UNA API (ej: Semantic Scholar)  â”‚
â”‚ Archivo: searchers.py lÃ­nea 112                                 â”‚
â”‚ FunciÃ³n: search_semantic_scholar()                              â”‚
â”‚                                                                 â”‚
â”‚ 1. Verifica rate limit (100 req/min)                            â”‚
â”‚    SI excede lÃ­mite â†’ Retorna [] vacÃ­o                          â”‚
â”‚                                                                 â”‚
â”‚ 2. Construye request HTTP:                                      â”‚
â”‚    GET https://api.semanticscholar.org/graph/v1/paper/search    â”‚
â”‚    params: {                                                    â”‚
â”‚      query: "machine learning neural networks models",          â”‚
â”‚      limit: 5,                                                  â”‚
â”‚      fields: "title,abstract,authors,publicationTypes"          â”‚
â”‚    }                                                            â”‚
â”‚                                                                 â”‚
â”‚ 3. Espera respuesta (timeout 8s)                                â”‚
â”‚                                                                 â”‚
â”‚ 4. Parsea JSON:                                                 â”‚
â”‚    {                                                            â”‚
â”‚      "data": [                                                  â”‚
â”‚        {                                                        â”‚
â”‚          "title": "Deep Learning",                              â”‚
â”‚          "abstract": "This paper presents...",                  â”‚
â”‚          "authors": [{"name": "Goodfellow"}],                   â”‚
â”‚          "publicationTypes": ["JournalArticle"]                 â”‚
â”‚        },                                                       â”‚
â”‚        ...                                                      â”‚
â”‚      ]                                                          â”‚
â”‚    }                                                            â”‚
â”‚                                                                 â”‚
â”‚ 5. Retorna lista de papers:                                     â”‚
â”‚    [                                                            â”‚
â”‚      {                                                          â”‚
â”‚        "title": "Deep Learning",                                â”‚
â”‚        "abstract": "This paper presents...",                    â”‚
â”‚        "author": "Goodfellow",                                  â”‚
â”‚        "type": "JournalArticle"                                 â”‚
â”‚      }                                                          â”‚
â”‚    ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 11: Agregar papers nuevos a FAISS                        â”‚
â”‚ Archivo: search_service.py lÃ­neas 133-148                     â”‚
â”‚                                                                 â”‚
â”‚ Para cada paper encontrado en APIs:                            â”‚
â”‚   1. Extrae abstract                                           â”‚
â”‚   2. Genera metadata:                                          â”‚
â”‚      {                                                          â”‚
â”‚        "title": "Deep Learning",                               â”‚
â”‚        "author": "Goodfellow",                                 â”‚
â”‚        "abstract": "This paper...",                            â”‚
â”‚        "source": "semantic_scholar",                           â”‚
â”‚        "type": "JournalArticle"                                â”‚
â”‚      }                                                          â”‚
â”‚                                                                 â”‚
â”‚   3. Llama a faiss_index.add_papers()                         â”‚
â”‚      â€¢ Genera embeddings de abstracts                          â”‚
â”‚      â€¢ Los normaliza (L2)                                      â”‚
â”‚      â€¢ Los agrega al Ã­ndice FAISS                             â”‚
â”‚      â€¢ Guarda metadata asociada                                â”‚
â”‚                                                                 â”‚
â”‚ RESULTADO: Papers quedan guardados para futuras bÃºsquedas ğŸ’¾  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 12: Calcular similitud con embeddings                    â”‚
â”‚ Archivo: search_service.py lÃ­nea 151                          â”‚
â”‚ FunciÃ³n: calculate_similarities_batch()                        â”‚
â”‚                                                                 â”‚
â”‚ 1. Preprocesa abstracts de papers encontrados                 â”‚
â”‚    Abstract: "This paper presents deep learning methods..."    â”‚
â”‚    â†’                                                            â”‚
â”‚    Procesado: "paper presents deep learning methods"           â”‚
â”‚                                                                 â”‚
â”‚ 2. Genera embeddings en BATCH (rÃ¡pido):                       â”‚
â”‚    Query: [0.12, -0.45, 0.78, ..., 0.34]                     â”‚
â”‚    Papers: [                                                   â”‚
â”‚      [0.15, -0.42, 0.81, ..., 0.31],  â† Paper 1              â”‚
â”‚      [0.08, -0.52, 0.65, ..., 0.29],  â† Paper 2              â”‚
â”‚      [-0.20, 0.15, -0.10, ..., 0.45]  â† Paper 3              â”‚
â”‚    ]                                                            â”‚
â”‚                                                                 â”‚
â”‚ 3. Calcula similitud coseno (NumPy vectorizado):              â”‚
â”‚    similarities = cosine_similarity(query, papers)             â”‚
â”‚    â†’ [0.892, 0.857, 0.234]  # Paper 1=89%, Paper 2=85%, ...  â”‚
â”‚                                                                 â”‚
â”‚ 4. Filtra por threshold (70%):                                â”‚
â”‚    Papers con similitud â‰¥70%:                                 â”‚
â”‚      âœ… Paper 1: 89.2%                                         â”‚
â”‚      âœ… Paper 2: 85.7%                                         â”‚
â”‚      âŒ Paper 3: 23.4% (descartado)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 13: Construir objetos SearchResult                       â”‚
â”‚ Archivo: search_service.py lÃ­neas 153-168                     â”‚
â”‚                                                                 â”‚
â”‚ Para cada paper con similitud â‰¥70%:                           â”‚
â”‚   SearchResult(                                                â”‚
â”‚     fuente = "semantic_scholar",                               â”‚
â”‚     texto_original = "Neural networks are models",             â”‚
â”‚     texto_encontrado = "This paper presents deep...",          â”‚
â”‚     porcentaje_match = 89.2,                                   â”‚
â”‚     documento_coincidente = "Deep Learning Book",              â”‚
â”‚     autor = "Goodfellow",                                      â”‚
â”‚     type_document = "JournalArticle"                           â”‚
â”‚   )                                                             â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Ordena por similitud (descendente)                          â”‚
â”‚ â€¢ Toma top 10 por query                                       â”‚
â”‚ â€¢ Guarda en cachÃ© Redis                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 14: Guardar Ã­ndice FAISS actualizado                     â”‚
â”‚ Archivo: search_service.py lÃ­nea 175                          â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Llama a faiss_index.save()                                   â”‚
â”‚ â€¢ Guarda Ã­ndice en: data/faiss_index.index                    â”‚
â”‚ â€¢ Guarda metadata en: data/faiss_index_metadata.pkl           â”‚
â”‚                                                                 â”‚
â”‚ AHORA los nuevos papers estÃ¡n disponibles para prÃ³ximas       â”‚
â”‚ bÃºsquedas sin necesidad de llamar APIs otra vez ğŸš€            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 15: Calcular mÃ©tricas de performance                     â”‚
â”‚ Archivo: search_service.py lÃ­neas 179-183                     â”‚
â”‚                                                                 â”‚
â”‚ elapsed = tiempo_final - tiempo_inicial                        â”‚
â”‚ throughput = textos_procesados / elapsed                       â”‚
â”‚                                                                 â”‚
â”‚ Imprime:                                                         â”‚
â”‚   âš¡ Procesamiento completado en 2.34s                          â”‚
â”‚   ğŸ“ˆ Throughput: 4.3 textos/s                                   â”‚
â”‚   ğŸ’¾ FAISS: 1523 papers indexados                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 16: Retornar al endpoint Flask                             â”‚
â”‚ Archivo: search_service.py lÃ­nea 185                            â”‚
â”‚                                                                 â”‚
â”‚ Retorna lista de SearchResult:                                  â”‚
â”‚   [                                                             â”‚
â”‚     SearchResult(fuente="semantic_scholar", ...),               â”‚
â”‚     SearchResult(fuente="arxiv", ...),                          â”‚
â”‚     SearchResult(fuente="pubmed", ...)                          â”‚
â”‚   ]                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 17: Flask convierte a JSON                                 â”‚
â”‚ Archivo: app.py lÃ­neas 89-96                                    â”‚
â”‚                                                                 â”‚
â”‚ response = [asdict(r) for r in results]                         â”‚
â”‚                                                                 â”‚
â”‚ Convierte SearchResult â†’ Dict:                                  â”‚
â”‚   {                                                             â”‚
â”‚     "fuente": "semantic_scholar",                               â”‚
â”‚     "texto_original": "Neural networks are models",             â”‚
â”‚     "texto_encontrado": "This paper presents...",               â”‚
â”‚     "porcentaje_match": 89.2,                                   â”‚
â”‚     "documento_coincidente": "Deep Learning Book",              â”‚
â”‚     "autor": "Goodfellow",                                      â”‚
â”‚     "type_document": "JournalArticle"                           â”‚
â”‚   }                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 18: Enviar respuesta HTTP                                  â”‚
â”‚ Archivo: app.py lÃ­neas 98-102                                   â”‚
â”‚                                                                 â”‚
â”‚ return jsonify({                                                â”‚
â”‚   "results": [                                                  â”‚
â”‚     {                                                           â”‚
â”‚       "fuente": "semantic_scholar",                             â”‚
â”‚       "texto_original": "Neural networks are models",           â”‚
â”‚       "texto_encontrado": "This paper presents deep...",        â”‚
â”‚       "porcentaje_match": 89.2,                                 â”‚
â”‚       "documento_coincidente": "Deep Learning Book",            â”‚
â”‚       "autor": "Goodfellow",                                    â”‚
â”‚       "type_document": "JournalArticle"                         â”‚
â”‚     },                                                          â”‚
â”‚     {                                                           â”‚
â”‚       "fuente": "arxiv",                                        â”‚
â”‚       "texto_original": "Deep learning uses layers",            â”‚
â”‚       "texto_encontrado": "We propose a novel...",              â”‚
â”‚       "porcentaje_match": 85.7,                                 â”‚
â”‚       "documento_coincidente": "CNN Architecture",              â”‚
â”‚       "autor": "LeCun",                                         â”‚
â”‚       "type_document": "preprint"                               â”‚
â”‚     }                                                           â”‚
â”‚   ],                                                            â”‚
â”‚   "count": 2,                                                   â”‚
â”‚   "processed_texts": 2,                                         â”‚
â”‚   "faiss_enabled": true                                         â”‚
â”‚ }), 200                                                         â”‚
â”‚                                                                 â”‚
â”‚ Status: 200 OK                                                  â”‚
â”‚ Content-Type: application/json                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USUARIO RECIBE RESPUESTA                                        â”‚
â”‚                                                                 â”‚
â”‚ JSON con papers similares encontrados âœ…                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜